str(tmp)
sort(tmp$X.4)
sort(tmp$X.4, decreasing=T)
order(tmp$X.4, decreasing=T)
tmp2 <- tmp[order(tmp$X.4, decreasing=T), ]
tmp2
tmp2[13,]
str(GDP)
is.character(GDP$X)
is.character(as.character(GDP$X)
)
GDP$X
GDP$X==""
!GDP$X==""
GDP_clean <-GDP[!GDP$X=="",]
School$CountryCode
School[1:3]
GDP[1:3,]
GDP[1:3]
GDP[1:2]
GDP[c(1,4)]
GDP[c(1,5)]
GDP[c(1,5,6)]
GDP[c(1,4)]
head(tmp)
tail(tmp)
tail(tmp, 10)
tail(tmp$CountryCode, 10)
tail(tmp, 10)[1:2]
GDP
GDP[190,]
GDP[191,]
GDP[1:190,]
GDP_clean <- GDP[1:190,]
tmp <- merge(School,GDP_clean, by.y='X', by.x="CountryCode", all=T)
head(tmp)
str(tmp)
tmp$CountryCode
School$CountryCode
School[1:2]
tmp <- merge(GDP_clean,School,by.x='X', by.y="CountryCode", all=T)
head(tmp)
str(tmp)
tmp <- merge(GDP_clean,School,by.x='X', by.y="CountryCode", all=F)
str(tmp)
tmp <- merge(GDP_clean,School,by.x='X', by.y="CountryCode")
str(tmp)
tmp$X
order(tmp$X.4)
tmp[order(tmp$X.4),]
tmp2 <- tmp[order(tmp$X.4),]
tmp2[13,]
tmp2 <- tmp[order(tmp$X.4, decreasing=T),]
tmp2[13,]
head(tmp2, 15)
levels(tmp$Income.Group)
str(GDP)
str(tmp)
table(tmp$X.4 ~ tmp$Income.Group)
mean(tmp$X.4[tmp$Income.group=="High income: OECD"])
tmp$Income.group=="High income: OECD"
tmp$Income.Group=="High income: OECD"
mean(tmp$X.4[tmp$Income.Group=="High income: OECD"])
mean(tmp$X.4[tmp$Income.Group=="High income: nonOECD"])
tmp2
which(tmp$Income.Group=="High income: nonOECD")
mean(which(tmp$Income.Group=="High income: nonOECD"))
str$tmp
mean(which(tmp2$Income.Group=="High income: nonOECD"))
mean(which(tmp2$Income.Group=="High income: OECD"))
tmp2$Income.Group
summary(tmp2)
quantile(tmp$X.4)
quantile(tmp$X.4, probs=c(0.2,0.4,0.6,0.8,1))
summary(quantile(tmp$X.4, probs=c(0.2,0.4,0.6,0.8,1)))
quantile(tmp$X.4, probs=c(0.2,0.4,0.6,0.8,1))
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
tmp2$GDPquant = cut(tmp2$X.4,breaks=quantile(tmp2$X.4, probs=c(0.2,0.4,0.6,0.8,1)))
table(tmp2$GDPquant)
str(tmp2)
str(tmp2)
tmp2$X.4
table(tmp2$GDPquant)
breaks=quantile(tmp2$X.4, probs=c(0.2,0.4,0.6,0.8,1)
)
breaks
table(tmp2$GDPquant, tmp2$Income.Group)
sort(GDP_clean$X)
sort(School$CountryCode)
tmp3 <- merge(GDP_clean, School, by.x=X, by.y=CountryCode)
tmp3 <- merge(GDP_clean, School, by.x= X, by.y=CountryCode)
GDP_clean$X
tmp3 <- merge(GDP_clean, School, by.x= 'X', by.y='CountryCode')
tmp3
str(tmp3)
tmp3 <- merge(School, GDP_clean, by.y= 'X', by.x='CountryCode')
sort(GDP_clean$X)
sort(School$CountryCode)
GDP$X==sort(School$CountryCode)
GDP$X ==School$CountryCode
GDP$X == School$CountryCode
GDP
match(GDP$X, School$CountryCode)
%in%(GDP$X, School$CountryCode)
%in%(School$CountryCode, GDP_clean)
match(School$CountryCode, GDP_clean)
match(School$CountryCode, GDP_clean$X)
is.na(match(School$CountryCode, GDP_clean$X))
sum(!is.na(match(School$CountryCode, GDP_clean$X)))
sum(!is.na(match(GDP_clean$X, School$CountryCode)))
match(GDP_clean$X, School$CountryCode)
is.na(match(GDP_clean$X, School$CountryCode))
which(is.na(match(GDP_clean$X, School$CountryCode)))
GDP_clean[which(is.na(match(GDP_clean$X, School$CountryCode))),]
View(GDP_clean)
View(School)
GDP_clean[which(is.na(match(School$CountryCode,GDP_clean$X))),1:2]
School[which(is.na(match(School$CountryCode,GDP_clean$X))),1:2]
View(tmp3)
tmp4 <- merge(GDP_clean,School, by.x='X', by.y="CountryCode")
tmp4 <- merge(GDP_clean,School, by.x='X', by.y="CountryCode", all=FALSE)
tmp4$X.4
order(tmp4$X.4)
tmp4$X.4[order(tmp4$X.4),]
tmp4$X.4[order(tmp4$X.4)]
tmp4$X.4[order(tmp4$X.4,decreasing=T)]
tmp5 <- tmp4[order(tmp4$X.4,decreasing=T)]
tmp5 <- tmp4[order(tmp4$X.4,decreasing=T),]
tmp5$X.4
tmp5$rank <-1:189
tmp5$rank
order(tmp5$rank,decreasing=T)
tmp5$Long.Name[order(tmp5$rank,decreasing=T),13]
tmp5[order(tmp5$rank,decreasing=T),13]
tmp5[order(tmp5$rank,decreasing=T),]
tmp6 <- tmp5[order(tmp5$rank,decreasing=T),]
tmp6[13,]
tmp5
tmp2
tmp2$X.4
tmp2$rank <- 1:189
match(GDP$X,School$CountryCode)
match(GDP_clean$X,School$CountryCode)
is.na(match(GDP_clean$X,School$CountryCode))
which(is.na(match(GDP_clean$X,School$CountryCode)))
GDP_clean[which(is.na(match(GDP_clean$X,School$CountryCode)))],
GDP_clean[which(is.na(match(GDP_clean$X,School$CountryCode))),]
match(tmp2$X, School$CountryCode)
is.na(match(tmp2$X, School$CountryCode))
which(is.na(match(tmp2$X, School$CountryCode)))
which(is.na(match(tmp2$X, GDP_clean$X)))
View(tmp2)
order(tmp2$X1)
order(tmp2$X1)
order(tmp2$X.1)
str(tmp2)
order(as.integer(as.character(tmp2$X.1)))
order(as.integer(as.character(tmp2$X.1)), decreasing=T)
tmp3 <- tmp2[order(as.integer(as.character(tmp2$X.1)), decreasing=T),]
head(tmp3$X.3,15)
set.seed(2)
rnorm(10)
rnorm(10)
set.seed(2)
rnorm(10)
rnorm(10)
library(datasets)
data(iris)
?iris
head(iris)
iris$Species=='virginica'
iris$Sepal.Length[iris$Species=='virginica']
mean(iris$Sepal.Length[iris$Species=='virginica'])
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 1, mean)
apply(iris, 1, mean)
colMeans(iris)
data(mtcars)
sapply(mtcars, cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
apply(mtcars, 2, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
tmp <- tapply(mtcars$hp, mtcars$cyl, mean)
tmp
tmp[2,1]
dim(tmp)
dim(tmp)tmp[1]
tmp[1]
tmp[1]-tmp[3]
debug(ls)
ls
debug(ls)
ls()
ls
cd ..
ls()
set.seed(1)
rpois(5, 2)
rnorm(10)
qnorm(10)
pnorm(10)
dnorm(10)
rbinom(10,10,0.5)
rbinom(10,10,0.5)
0.88*0.88
x <- 1:4
p <- x/sum(x)
temp <- rbind(x,p)
temp
x*p
sum(x*p)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
library(ggplot2)
qplot(Wind, Ozone, data=airquality, facets =.~ factor(Month)
)
qplot(Wind, Ozone, data=airquality, facets =.~ factor(Month))
airquality <- transform(airquality, Month=as.factor(Month))
qplot(Wind, Ozone, data=airquality, facets =.~ Month)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, panel=panel.loess)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, smooth='loess')
qplot(votes, rating, data = movies) + stat_smooth("loess")
rm(list=ls())
rm()
clear()
par(mar= rep(0.2,4))
dataMatrix <- matrix(1:400: nrow=10)
dataMatrix <- matrix(1:400, nrow=10)
image(1:10,1:40)
image(1:10,1:40, t(dataMatrix)[,nrow(dataMatrix):1])
dataMatrix <- matrix(rnorm(400), nrow=10)
image(1:10,1:40, t(dataMatrix)[,nrow(dataMatrix):1])
dataMatrix <- matrix(rnorm(400), nrow=40)
image(1:10,1:40, t(dataMatrix)[,nrow(dataMatrix):1])
dataMatrix <- matrix(1:400, nrow=40)
image(1:10,1:40, t(dataMatrix)[,nrow(dataMatrix):1])
heatmap(dataMatrix)
0.7/0.8
(0.75*0.3)/(0.75*0.3+0.48*0.7)
pnorm(70,80,10)
pnorm(70, mean=80, sd=10, lower.tail=FALSE)
qnorm(0.95, 1100, 75)
1223-1100
qnorm(0.05, 1100, 75)
977-1100
qnorm(0.975, 1100, 75)
qnorm(0.977, 1100, 75)
qnorm(0.978, 1100, 75)
dnorm(0.95, 1100, 75)
dnorm(100, 1100, 75)
pbinom(3, size=5, prob=0.5, lower.tail=false)
pbinom(3, size=5, prob=0.5, lower.tail=F)
pbinom(3.5, size=5, prob=0.5, lower.tail=F)
pbinom(4, size=5, prob=0.5, lower.tail=F)
0.5*0.5*0.5*0.5*0.5
pnorm(93,100,10)
pnorm(90,100,10)
pnorm(20,100,10)
pnorm(80,100,10)
0.93*0.05/(0.93*0.05 - 0.12*0.95)
0.93*0.05/(0.93*0.05 + 0.12*0.95)
0.88*0.95/(0.88*0.95+0.07*0.05)
qnorm(0.95, 100,10)
qnorm(0.95, 100, 10/sqrt(50))
qnorm(0.95, 1100, 75)
qnorm(0.95, 1100, 75/sqrt(100))
pbinom(4, size=6, prob=0.5, lower.tail=F)
pbinom(4, size=6, prob=0.5, lower.tail=T)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail=F)
)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail=T)
)
pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail=T)
pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail=F)
pnorm(14, mean=15, sd=10/sqrt(10), lower.tail=T)
pnorm(16, mean=15, sd=10/sqrt(10), lower.tail=T)
pnorm(16, mean=15, sd=10/sqrt(100), lower.tail=T)-
pnorm(16, mean=15, sd=10/sqrt(100), lower.tail=T)
pnorm(14, mean=15, sd=10/sqrt(100), lower.tail=T)
pnorm(16, mean=15, sd=10/sqrt(100), lower.tail=T)-pnorm(14, mean=15, sd=10/sqrt(100), lower.tail=T)
1/12/1000
ppois(10, 5*3)
ppois(15, 5*3)
ppois(5, 5)
ppois(5, 5, lower.tail=F)
ppois(10, 15, lower.tail=F)
ppois(10, 15)
choose(9,3)
sqrt((1/12)/100)
0.1/0.2
qnorm(30,10)
qnorm(0.95,30,10)
qnorm(0.95, 30, 1)
mtcars
t.test(mtcars$mpg)
qt(0.95,df=3)*1/3
qnorm(0.95,1100,30/9)
qnorm(0.95,1100,30/sqrt(9))
qnorm(0.975,1100,30/sqrt(9))
qnorm(0.95,1100,30/9)
qt(0.95,df=3)*1/3
qt(0.95,df=8)*1/3
2*qt(0.95,df=3)*3
2/qt(0.95,df=3)*
3
qt(0.95,df=3)
mt4 <- mtcars$mpg[mtcars$cyl==4]
mt6 <- mtcars$mpg[mtcars$cyl==6]
ttest(mt4,mt6,var.equal=T)
t.test(mt4,mt6,var.equal=T)
t.test(mt4,mt6,var.equal=F)
0.68*0.68
sp <- sqrt((9*0.6^4))
sp <- sqrt((9*0.6^4+9*0.68^4))
sp <- sqrt((9*0.6^4+9*0.68^4)/10+10-2)
sp <- sqrt((9*0.6^4+9*0.68^4)/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((9*0.6^2+9*0.68^2)/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((9*0.6^4+9*0.68^4)/10+10-2)
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((9*0.6^4+9*0.68^4)/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.95,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((99*0.5^2+99*2^2)/(100+100-2))
qt(0.975,df=15.04)
sp <- sqrt((9*0.6^4+9*0.68^4)/(10+10-2))
3-5+c(-1,1)*qt(0.975,19)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((9*0.6^2+9*0.68^2)/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((99*0.5^2+99*2^2)/(100+100-2))
4-6+c(-1,1)*qt(0.975,198)*sp*(1/100+1/100)^0.5
6-4+c(-1,1)*qt(0.975,198)*sp*(1/100+1/100)^0.5
sp <- sqrt((8*1.5^2+8*1.8^2)/(9+9-2))
sp
-3-1+c(-1,1)*qt(0.975,17)*sp*(1/9+1/9)^0.5
sp*sp
spsr <-((8*1.5^2+8*1.8^2)/(9+9-2))
-3-1+c(-1,1)*qt(0.975,17)*sp*(1/9+1/9)^0.5
-3-1+c(-1,1)*qt(0.975,16)*sp*(1/9+1/9)^0.5
-3-1+c(-1,1)*qt(0.95,16)*sp*(1/9+1/9)^0.5
-3-1+c(-1,1)*qt(0.95,17)*sp*(1/9+1/9)^0.5
qt(0.975,8)
2*sqrt(9)/(qt(0.975,8))
-2+c(-1,1)*qt(0.975,8)*2.60/3
sp <- sqrt((9*((0.6)^2)^2+(9*((0.68)^2)^2))/(10+10-2)^0.5)
sp <- sqrt((9*((0.6)^2)^2+(9*((0.68)^2)^2))/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.95,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.99,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.995,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.95,18)*sp*(1/10+1/10)^0.5
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
sp <- sqrt((9*(0.6)^2+(9*(0.68)^2))/(10+10-2))
3-5+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
x <- rnorm(n=40,mean=10,sd=2)
y <- x*(2+rnorm(n=40,mean=1, sd=1))
plot(x,y)
lm(y~x)
tmp <- lm(y~x)
summary(lm)
summary(lm(y~x))
summary(tmp)
summary(tmp$coefficients)
summary(tmp$coeff)
summary(tmp$coefficient[2,4])
tmp$coefficient[2,4]
tmp$coefficient
tmp$coefficient[2]
tmp$coefficient[2,4]
tmp$coeff[2,4]
summary(tmp)
summary(tmp)[2,]
summary(tmp)[2,4]
summary(tmp)$coeff
summary(tmp)$coeff[2,4]
help(ppois)
qnorm(0.95, mean=12, sd=4/sqrt(100), lower.tail=F)
qnorm(0.95, mean=12, sd=4/sqrt(100), lower.tail=T)
baseline <- c(140,138,150,148,135)
Week2 <- c(132,135,151,146,130)
t.test(baseline,Week2, alternative="two.sided", paired=TRUE)
t.test(Week2, baseline, alternative="two.sided", paired=TRUE)
t.test(Week2, baseline, alternative="two.sided", paired=F)
t.test(Week2, baseline, alternative="two.sided", paired=T)
qnorm(0.975,1100,10)
qnorm(0.975,1100,30)
qnorm(c(0.025,0.975),1100,30)
qnorm(c(0.025,0.975),1100,10)
round(qnorm(c(0.025,0.975),1100,10),0)
pbinom(2,size=4, prob=0.5, lower.tail=F)
10/1787*1000
10/1787*10001/100*1000
1/100*1000
ppois(5,10, lower.tail.=F)
ppois(5,10, lower.tail=F)
source('~/.active-rstudio-document', echo=TRUE)
m1 <- 1
m2 <- -3
s1 <- 1.8
s2 <- 1.5
n1 <- n2 <- 9
t.test2(m1,m2,s1,s2,n1,n2)
s1 <- 0.6
s2 <- 0.5
t.test2(m1,m2,s1,s2,n1,n2)
sqrt((0.5*16^2)/9+(0.6*16^2)/9)
-4/sqrt((0.5*16^2)/9+(0.6*16^2)/9)
-4/sqrt((1.5*16^2)/9+(1.8*16^2)/9)
pt(-4/sqrt((1.5*16^2)/9+(1.8*16^2)/9), df=16)
pt(-4/sqrt((0.5*16^2)/9+(0.6*16^2)/9), df=16)
power.t.test(n=100, delta=0.01, sd=0.04, type('one.sample'), alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.004, type='one.sample', alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.95)
power.t.test(power=0.9, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05)
z=(44-42.04)/(12/sqrt(288))
pnorm(z)
sqrt(288)
power.t.test(n=100, delta=0.01, sd=0.04, type('one.sample'), alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.004, type='one.sample', alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.004, type='one.sample', alternative="one.sided", sig.level=0.95)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.95)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05)
power.t.test(n=100, delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05, power=0.9)
power.t.test(delta=0.01, sd=0.04, type='one.sample', alternative="one.sided", sig.level=0.05, power=0.9)
install.packages("knitr")
date()
weekday(date())
weekdays(date())
weekdays(strptime(date()))
date()$wday
today <- date()
weekdays(today)
today$wday
str(today)
weekdays.Date(date())
Reproducible Research
========================================================
# Peer Assessment 1
Data is read from activity.csv and the format of the date column is changed to date format (POSIXlt). The format in the interval
```{r}
Sys.setenv(LANGUAGE="en")
setwd('C:/Users/Omar/Documents/R/Files/GitHubRepos/ReproducibleResearchPeerAssessment1')
activity <- read.csv('activity.csv')
activity$date <- strptime(as.character(activity$date),tz="GMT", "%Y-%m-%d")
activity$interval <- strptime(formatC(activity$interval/100, digits=2, format="f", width=5, flag=0),format="%H.%M")
```
Ignoring NAs the total number of steps each day is calucated using aggregate() and a histogram of for steps per day is drawn.
```{r fig.width=7, fig.height=6}
SumSteps_per_day <- aggregate(activity$steps, by = list(Date = as.character(activity$date)), sum)
SumSteps_per_day
hist(SumSteps_per_day$x, main= "Histogram of total steps taken per day", xlab = "Steps per Day", ylab ="Number of days")
mean_sum_steps_per_day <- mean(SumSteps_per_day$x, na.rm=T)
median_sum_steps_per_day <-median(SumSteps_per_day$x, na.rm=T)
```
The mean number of steps observed each day was `r format(mean_sum_steps_per_day, digits=6)` and the median number of steps per day was `r format(median_sum_steps_per_day, digits=6)`.
```{r}
Mean_steps_per_timeofDay <- aggregate(activity$steps, by = list(strftime(activity$interval, "%H:%M")), FUN=mean, na.rm=T)
plot(strptime(Mean_steps_per_timeofDay$Group.1, "%H:%M"), Mean_steps_per_timeofDay$x, type='l', main="Mean number of steps for each 5 minute interval", ylab= "Number of Steps", xlab="Time of day")
MaxSteps <- max(Mean_steps_per_timeofDay$x)
MaxStepTime <- Mean_steps_per_timeofDay$Group.1[Mean_steps_per_timeofDay$x==MaxSteps]
```
The interval with the maximum number of steps of steps on average is the 5 minute interval that starts at `r MaxStepTime` with an average of `r format(MaxSteps, digits=4)` steps in the interval.
```{r}
NAs <- sum(is.na(activity$steps))
unique(activity$date[is.na(activity$steps)])
```
There are a total of `r NAs` missing values for the number of steps in the dataset.  These missing values fall on 8 days where all data is missing.
I create a duplicate of the acitivty dataset, called activity_imputed.  To impute the missing values I add to each missing data point the mean number of steps for that interval from the rest of the dataset.
```{r}
activity_imputed <- activity
activity_imputed$time <- strftime(activity_imputed$interval, format("%H:%M"))
activity_imputed <- merge(activity_imputed, Mean_steps_per_timeofDay, by.x="time", by.y="Group.1", all.x=T)
activity_imputed$steps[is.na(activity_imputed$steps)] <- activity_imputed$x[is.na(activity_imputed$steps)]
SumSteps_per_day_imputed <- aggregate(activity_imputed$steps, by = list(Date = as.character(activity_imputed$date)), sum)
hist(SumSteps_per_day_imputed$x, main= "Histogram of total steps taken per day with NA data imputed", xlab = "Steps per Day", ylab ="Number of days")
```
The histogram of total number ofsteps per day with the imputed data is very similar to the histogram without the imputed dat except that the middle bar his higher.  This is somewhat expected as the 8 days that are imputed all get the same value, the mean, as their total number of steps per day.  This is due to the fact that the imputation is very limited.
```{r}
mean_sum_steps_per_day_imp <- mean(SumSteps_per_day_imputed$x, na.rm=T)
median_sum_steps_per_day_imp <-median(SumSteps_per_day_imputed$x, na.rm=T)
```
The mean number of steps observed each day after imputing the missing values with the mean of each interval was `r format(mean_sum_steps_per_day_imp, digits=6)` steps and the median number of steps per day was `r format(median_sum_steps_per_day_imp, digits=6)`.
The imputation of the missing values has no effect on the mean sum of steps per day.  This is due to the fact that all the missing measurements fall on 8 days where no data is available.  Therefore the sum of each of these days is the mean of all the other days. The median value is not the same as with the un-imputed data but changes slightly and becomes the same as the mean.  This is beacuse 8 values of the mean are added to the dataset.
All in all the imputation does not have a significant effect on the results, this is partly due to the fact that the imputation is very rudimentary and might not be approriate in this case.
```{r}
library(ggplot2)
activity_imputed$WeekDay_End[!weekdays(activity_imputed$date) %in% c('Saturday', 'Sunday') ] <- 'Weekday'
activity_imputed$WeekDay_End[weekdays(activity_imputed$date) %in% c('Saturday', 'Sunday') ] <- 'Weekend'
activity_imputed$WeekDay_End <- as.factor(activity_imputed$WeekDay_End)
Mean_steps_per_timeofDay_Weekend_Weekday <- aggregate(steps ~ time + WeekDay_End, data=activity_imputed, FUN=mean)
nrow(Mean_steps_per_timeofDay_Weekend_Weekday)
head(weekdays(activity_imputed$date))
ggplot(Mean_steps_per_timeofDay_Weekend_Weekday,aes(x=strptime(time,"%H:%M"), y=steps))+geom_line() +facet_grid(.~WeekDay_End)
#plot(strptime(Mean_steps_per_timeofDay_Weekend_Weekday$time[Mean_steps_per_timeofDay_Weekend_Weekday$WeekDay_End=='Weekend'],"%H:%M"),Mean_steps_per_timeofDay_Weekend_Weekday$steps[Mean_steps_per_timeofDay_Weekend_Weekday$WeekDay_End=='Weekend'], type = 'l', main="Weekday", ylab = "Mean steps per 5 min interval", xlab="Time of day")
```
```
weekdays(activity_imputed$date)
library("scales", lib.loc="C:/Users/Omar/Documents/R/win-library/3.1")
